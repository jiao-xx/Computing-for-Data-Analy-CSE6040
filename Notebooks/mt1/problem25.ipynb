{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Midterm 1, Fall 2021: Chess Ratings #\n",
    "\n",
    "_Version 1.0_\n",
    "\n",
    "Change Log:\n",
    "1.0 - Initial Release\n",
    "\n",
    "This problem builds on your knowledge of **Python data structures, string processing, and implementing mathematical functions**.\n",
    "\n",
    "For other preliminaries and pointers, refer back to the Piazza post titled **\"Midterm 1 Release Notes\"**.\n",
    "- Total Exercises: **8**  \n",
    "- Total Points: **16**\n",
    "- Time Limit: **3 Hours**\n",
    "\n",
    "Each exercise builds logically on the previous one, but you may **solve them in any order**. That is, if you can't solve an exercise, you can still move on and try the next one. **However, if you see a code cell introduced by the phrase, \"Sample result for ...\", please run it.** Some demo cells in the notebook may depend on these precomputed results.\n",
    "\n",
    "The point values of individual exercises are as follows:\n",
    "\n",
    "- Exercise 0: 3 points\n",
    "- Exercise 1: 2 points\n",
    "- Exercise 2: 1 points\n",
    "- Exercise 3: 2 points\n",
    "- Exercise 4: 1 points\n",
    "- Exercise 5: 3 points\n",
    "- Exercise 6: 2 points\n",
    "- Exercise 7: 2 points\n",
    "\n",
    "\n",
    "**Good luck!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Elo Ratings\n",
    "\n",
    "The Elo (rhymes with \"Hello\") rating system is a widely used method for quantifying relative skill levels of players in a game or sport. The method was originally used to rate chess players and is named for its creator, Arpad Elo. This system is very simple but is able to rate players much more effectively than a win/loss record.\n",
    "\n",
    "On a high level, the winning player in a game takes rating points away from the losing player. How many points change hands is determined by the difference in the initial ratings of each player. For example, if a highly rated player records a victory over a lower rated player, then they would gain only a few points. This is reflective of the highly rated player being expected to win. However, if the lower rated player is able to pull off an upset, a larger quantity of points would be exchanged. The idea is that over time the system will adjust players' ratings to their true relative skill levels. Additionally, the difference in Elo ratings between two players can be used to calculate the expectation for the number of wins each player would accrue, which is often expressed as \"win probability\". \n",
    "\n",
    "Here we will extract data from a recent chess tournament that captures players' ratings at the start of the tournament and the outcome of all games played. We will then use that data to calculate expected wins based on the matchups and compare our expectation with the observed results. Finally we will determine the updated Elo ratings for the players. There are many variations on this system, but here we will use the original version. You can find more information about the Elo rating system [here](https://en.wikipedia.org/wiki/Elo_rating_system)\n",
    "\n",
    "Let's get started by taking a look at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48.1 MiB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "\n",
    "import run_tests as test_utils\n",
    "raw_data = test_utils.read_raw_data('Bucharest2021.pgn')\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Take note of how the data is **split** into sections by **blank lines** (`'\\n\\n'`); this fact might be useful later on! _(hint! hint!)_ Here are the first 4 sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Event \"Superbet Classic 2021\"]\n",
      "[Site \"Bucharest ROU\"]\n",
      "[Date \"2021.06.05\"]\n",
      "[Round \"1.5\"]\n",
      "[White \"Deac,Bogdan-Daniel\"]\n",
      "[Black \"Giri,A\"]\n",
      "[Result \"1/2-1/2\"]\n",
      "[WhiteElo \"2627\"]\n",
      "[BlackElo \"2780\"]\n",
      "[ECO \"D43\"]\n",
      "\n",
      "1.d4 d5 2.c4 c6 3.Nc3 Nf6 4.Nf3 e6 5.Bg5 h6 6.Bh4 dxc4 7.e4 g5 8.Bg3 b5 9.Be2 Bb7\n",
      "10.Qc2 Nh5 11.Rd1 Nxg3 12.hxg3 Na6 13.a3 Bg7 14.e5 Qe7 15.Ne4 O-O-O 16.Nd6+ Rxd6\n",
      "17.exd6 Qxd6 18.O-O g4 19.Ne5 Bxe5 20.dxe5 Qxe5 21.Bxg4 h5 22.Rfe1 Qf6 23.Bf3 h4\n",
      "24.b3 cxb3 25.Qxb3 hxg3 26.fxg3 Qg7 27.Qd3 Nc7 28.Qd6 c5 29.Qd7+ Kb8 30.Bxb7 Kxb7\n",
      "31.Rxe6 Qxg3 32.Qc6+ Kb8 33.Qd6 Qxd6 34.Rexd6 Kb7 35.Rf6 Rh7 36.Rd7 b4 37.axb4 cxb4\n",
      "38.Kf2 a5 39.Ke2 Rg7 40.Rfxf7 Rxg2+ 41.Kd1 Rg1+ 42.Kc2 Rg2+ 43.Kb1 Rg1+ 44.Kb2 Rg2+\n",
      "45.Kb1 Rg1+ 46.Kb2 Rg2+ 47.Kb1 Rg1+  1/2-1/2\n",
      "\n",
      "[Event \"Superbet Classic 2021\"]\n",
      "[Site \"Bucharest ROU\"]\n",
      "[Date \"2021.06.05\"]\n",
      "[Round \"1.4\"]\n",
      "[White \"Lupulescu,C\"]\n",
      "[Black \"Aronian,L\"]\n",
      "[Result \"1/2-1/2\"]\n",
      "[WhiteElo \"2656\"]\n",
      "[BlackElo \"2781\"]\n",
      "[ECO \"E39\"]\n",
      "\n",
      "1.d4 Nf6 2.c4 e6 3.Nc3 Bb4 4.Qc2 c5 5.dxc5 O-O 6.Nf3 Na6 7.g3 Nxc5 8.Bg2 Nce4\n",
      "9.O-O Nxc3 10.bxc3 Be7 11.e4 d6 12.e5 dxe5 13.Nxe5 Qc7 14.Qe2 Nd7 15.Bf4 Nxe5\n",
      "16.Bxe5 Bd6 17.Bxd6 Qxd6 18.Qe3 Qc7 19.Rfb1 Qxc4 20.Bxb7 Bxb7 21.Rxb7 h6\n",
      "22.Rxa7 Rxa7 23.Qxa7 Qxc3 24.Rb1 Qc2 25.Rb8 Qd1+ 26.Kg2 Qd5+ 27.Kg1 Qd1+\n",
      "28.Kg2 Qd5+ 29.Kg1 Qd1+  1/2-1/2\n"
     ]
    }
   ],
   "source": [
    "demo_raw_data = '\\n\\n'.join(raw_data.split('\\n\\n')[:4])\n",
    "print(demo_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The sections in the raw data alternate between **metadata** and **moves data**. The metadata is information about the game, such as who is playing with what pieces, the ratings of each player, and the results of the game. The moves data contains a record of each chess move executed in the game. Since players' Elo ratings are only affected by the outcomes of the games, we are primarily concerned with the metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 0 (3 points)\n",
    "\n",
    "The first thing we need to do in our analysis is get the data in a more structured form. \n",
    "\n",
    "Fill out the function `extract_games(raw_data)` in the code cell below with the following requirements:\n",
    "\n",
    "Given a string read from a text file `raw_data`, extract the following information about each game and store in a **list of dictionaries** `games`. Below are details for what one of these dictionaries should look like: \n",
    "* `games[i]['white_player']` - String - Name of the player assigned the white pieces.\n",
    "  * Example from `raw_data`: [White \"Deac,Bogdan-Daniel\"]\n",
    "  * Example value: `'Deac,Bogdan-Daniel'`  \n",
    "  * Value type: `str`  \n",
    "  \n",
    "  \n",
    "* `games[i]['black_player']` - String - Name of the player assigned the black pieces.\n",
    "  * Example from `raw_data`: [Black \"Giri,A\"]\n",
    "  * Example value: `'Giri,A'`  \n",
    "  * Value type: `str`\n",
    "    \n",
    "\n",
    "* `games[i]['white_rating']` - Integer - Pre-tournament rating of the white player.\n",
    "  * Example from `raw_data`: [WhiteElo \"2627\"]\n",
    "  * Example value: `2627`  \n",
    "  * Value type: `int`\n",
    "    \n",
    "    \n",
    "* `games[i]['black_rating']` - Integer - Pre-tournament rating of the black player.\n",
    "  * Example from `raw_data`: [BlackElo \"2780\"]\n",
    "  * Example value: `2780`  \n",
    "  * Value type: `int`\n",
    "    \n",
    "    \n",
    "* `games[i]['result']` - String - Result of the game.\n",
    "  * Example from `raw_data`: [Result \"1/2-1/2\"]\n",
    "  * Example value: `'1/2-1/2'`\n",
    "  * Value type: `str`\n",
    "\n",
    "You may assume that the required metadata is included, that sections are separated by blank lines, and that the sections alternate between metadata and moves data (starting with metadata). Additional metadata tags (beyond the 5 you are tasked with extracting) may be present, but they should be ignored. The ordering of the metadata **may be different** from the example above. Additionally, the moves data sections **may not be formatted** the same way as the example above.\n",
    "\n",
    "A demo of your function run on the `demo_raw_data` defined above is included in the solution cell. The result should be:\n",
    "```\n",
    "[{  'white_player': 'Deac,Bogdan-Daniel',\n",
    "    'black_player': 'Giri,A',\n",
    "    'result': '1/2-1/2',\n",
    "    'white_rating': 2627,\n",
    "    'black_rating': 2780},\n",
    "  { 'white_player': 'Lupulescu,C', \n",
    "    'black_player': 'Aronian,L', \n",
    "    'result': '1/2-1/2', \n",
    "    'white_rating': 2656, \n",
    "    'black_rating': 2781}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To help you get started, consider the following snippet, which converts `demo_raw_data` into a nested list of lists. A similar strategy may be helpful in processing the `raw_data` parameter in the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(demo_metadata_list[0]): <class 'list'>\n",
      "type(demo_metadata_list[0][0]): <class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['[Event \"Superbet Classic 2021\"]',\n",
       "  '[Site \"Bucharest ROU\"]',\n",
       "  '[Date \"2021.06.05\"]',\n",
       "  '[Round \"1.5\"]',\n",
       "  '[White \"Deac,Bogdan-Daniel\"]',\n",
       "  '[Black \"Giri,A\"]',\n",
       "  '[Result \"1/2-1/2\"]',\n",
       "  '[WhiteElo \"2627\"]',\n",
       "  '[BlackElo \"2780\"]',\n",
       "  '[ECO \"D43\"]'],\n",
       " ['[Event \"Superbet Classic 2021\"]',\n",
       "  '[Site \"Bucharest ROU\"]',\n",
       "  '[Date \"2021.06.05\"]',\n",
       "  '[Round \"1.4\"]',\n",
       "  '[White \"Lupulescu,C\"]',\n",
       "  '[Black \"Aronian,L\"]',\n",
       "  '[Result \"1/2-1/2\"]',\n",
       "  '[WhiteElo \"2656\"]',\n",
       "  '[BlackElo \"2781\"]',\n",
       "  '[ECO \"E39\"]']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_metadata_list = [metadata.splitlines() for metadata in demo_raw_data.split('\\n\\n')[::2]]\n",
    "print(f'type(demo_metadata_list[0]): {type(demo_metadata_list[0])}') # outer list items are lists\n",
    "print(f'type(demo_metadata_list[0][0]): {type(demo_metadata_list[0][0])}') # inner list items are strings\n",
    "demo_metadata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "# [['[Event \"Superbet Classic 2021\"]',\n",
    "#   '[Site \"Bucharest ROU\"]',\n",
    "#   '[Date \"2021.06.05\"]',\n",
    "#   '[Round \"1.5\"]',\n",
    "#   '[White \"Deac,Bogdan-Daniel\"]',\n",
    "#   '[Black \"Giri,A\"]',\n",
    "#   '[Result \"1/2-1/2\"]',\n",
    "#   '[WhiteElo \"2627\"]',\n",
    "#   '[BlackElo \"2780\"]',\n",
    "#   '[ECO \"D43\"]'],\n",
    "\n",
    "# Output\n",
    "#  { 'white_player': 'Lupulescu,C', \n",
    "#     'black_player': 'Aronian,L', \n",
    "#     'result': '1/2-1/2', \n",
    "#     'white_rating': 2656, \n",
    "#     'black_rating': 2781}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'black_player': 'Giri,A',\n",
       "  'result': '1/2-1/2',\n",
       "  'white_rating': 2627,\n",
       "  'black_rating': 2780},\n",
       " {'black_player': 'Aronian,L',\n",
       "  'result': '1/2-1/2',\n",
       "  'white_rating': 2656,\n",
       "  'black_rating': 2781}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # METHOD 0\n",
    "# 1. define return, a list & a dict\n",
    "# 2. need to define the variables that we are oking for in the input data,\n",
    "#     so that I know I have the correct elements\n",
    "# 3. loop over the string to split the string \n",
    "#     a. loop over each game to split the component\n",
    "#     b. for each componant\n",
    "#         1. remove the brackets\n",
    "#         2. remove the double quotes\n",
    "#         3. split it into its values, could be two or more values\n",
    "#         4. if value[0] is one of the keys that I want, then set my\n",
    "#         return dict to value[1]\n",
    "#     c. append the dict to the return list\n",
    "# 4. return the list\n",
    "\n",
    "def extract_games(raw_data):\n",
    "    \n",
    "    ret_list = []\n",
    "    # define somethig that allow us to detect the string calue \n",
    "    translate_dict_strings = {'white': 'white_player', 'Black': 'black_player', 'Result': 'result'}\n",
    "    translate_dict_integers = {'WhiteElo': 'white_rating', 'BlackElo':'black_rating'}\n",
    "\n",
    "\n",
    "    for metadata in raw_data.split('\\n\\n')[::2]:\n",
    "        ret_dict= {}\n",
    "        for game in metadata.splitlines():\n",
    "            game1 = game[1:-1]\n",
    "            game2 = game1.replace('\"', '')\n",
    "    #         print(game2)\n",
    "            game3 = game2.split()\n",
    "    #         print(game3)\n",
    "            key = game3[0]\n",
    "            value = game3[1]\n",
    "\n",
    "            if key in translate_dict_strings:\n",
    "                ret_dict[translate_dict_strings[key]] = value\n",
    "            if key in translate_dict_integers:\n",
    "                ret_dict[translate_dict_integers[key]] = int(value)\n",
    "\n",
    "        ret_list.append(ret_dict)\n",
    "\n",
    "    return ret_list\n",
    "\n",
    "# Demo\n",
    "extract_games(demo_raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deac,Bogdan-Daniel\n",
      "Deac,Bogdan-Daniel\n"
     ]
    }
   ],
   "source": [
    "# METHOD 1\n",
    "import re\n",
    "txt = ''' \n",
    "    [Event \"Superbet Classic 2021\"]\n",
    "    [Site \"Bucharest ROU\"]\n",
    "    [Date \"2021.06.05\"]\n",
    "    [Round \"1.5\"]\n",
    "    [White \"Deac,Bogdan-Daniel\"]\n",
    "    [Black \"Giri,A\"]\n",
    "    [Result \"1/2-1/2\"]\n",
    "    [WhiteElo \"2627\"]\n",
    "    [BlackElo \"2780\"]\n",
    "    [ECO \"D43\"]\n",
    "    '''\n",
    "m = re.search(r'\\[White\\s\"(.+?)\"\\]', txt)\n",
    "print(m.groups()[0])\n",
    "\n",
    "# create a new helper function\n",
    "def extract_item(key,txt):\n",
    "    m_list = re.search(key, txt).groups()\n",
    "    return m_list[0]\n",
    "\n",
    "print(extract_item(r'\\[White\\s\"(.+?)\"\\]',txt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'white_player': 'Deac,Bogdan-Daniel',\n",
       "  'black_player': 'Giri,A',\n",
       "  'result': '1/2-1/2',\n",
       "  'white_rating': 2627,\n",
       "  'black_rating': 2780},\n",
       " {'white_player': 'Lupulescu,C',\n",
       "  'black_player': 'Aronian,L',\n",
       "  'result': '1/2-1/2',\n",
       "  'white_rating': 2656,\n",
       "  'black_rating': 2781}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# METHOD 1\n",
    "import re\n",
    "\n",
    "# create a new helper function\n",
    "def extract_item(key,txt):\n",
    "    m_list = re.search(key, txt).groups()\n",
    "    return m_list[0]\n",
    "\n",
    "def extract_games(raw_data):\n",
    "    import re\n",
    "    games = []\n",
    "    for data in raw_data.split('\\n\\n')[::2]:\n",
    "        data_dict = { 'white_player': extract_item(r'\\[White\\s\"(.+?)\"\\]',data), \n",
    "                    'black_player': extract_item(r'\\[Black\\s\"(.+?)\"\\]',data), \n",
    "                    'result': extract_item(r'\\[Result\\s\"(.+?)\"\\]',data), \n",
    "                    'white_rating': int(extract_item(r'\\[WhiteElo\\s\"(.+?)\"\\]',data)), \n",
    "                    'black_rating': int(extract_item(r'\\[BlackElo\\s\"(.+?)\"\\]',data)),     \n",
    "                     }\n",
    "        games.append(data_dict)\n",
    "    return games\n",
    "   \n",
    "\n",
    "# Demo\n",
    "extract_games(demo_raw_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex0_test",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'48.1 MiB'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ex0_test`: Test cell\n",
    "from run_tests import ex0_test\n",
    "for _ in range(100):\n",
    "    ex0_test(10, 4, extract_games)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Run the following cell, even if you skipped Exercise 0.**\n",
    "\n",
    "We are loading a pre-computed solution that will be used in the following sections. The first two sections items in the list are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'white_player': 'Deac,Bogdan-Daniel', 'black_player': 'Giri,A', 'result': '1/2-1/2', 'white_rating': 2627, 'black_rating': 2780}, {'white_player': 'Lupulescu,C', 'black_player': 'Aronian,L', 'result': '1/2-1/2', 'white_rating': 2656, 'black_rating': 2781}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'48.1 MiB'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample result for ex0\n",
    "games_metadata = test_utils.read_pickle('games_metadata')\n",
    "print(games_metadata[:2])\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1 (2 points)\n",
    "\n",
    "The next bit of information we will need in our analysis is the outcome of each player's games paired with their opponent.\n",
    "\n",
    "Fill out the function `extract_player_results(games)` in the code cell below with the following requirements:\n",
    "\n",
    "Given `games`, a list of dictionaries containing the metadata for each game, create dictionary `player_results` mapping each player's name to a list of the outcomes of that player's games. Each outcome should include the opponent's name (String) and the number of points that the player received (Float) as the outcome of the game as a Tuple. \n",
    "\n",
    "The order of tuples in the list associated with each player should be the **same as the order of the matchups in `games`**. \n",
    "\n",
    "You should interpret the value associated with `'result'` as `\"<white player points>-<black player points>\"` separated by a dash \"-\". There are three possible outcomes of a game of chess: White wins (`'1-0'`), black wins (`'0-1'`), or draw (`'1/2-1/2'`).\n",
    "\n",
    "For example, if the input is:\n",
    "\n",
    "`[{'white_player': 'Dwight Schrute', 'black_player: 'Jim Halpert', 'result': '1-0'}, {'white_player': 'Stanley Hudson', 'black_player': 'Dwight Schrute', 'result': '1/2-1/2'}]`\n",
    "\n",
    "Then the output should be:\n",
    "\n",
    "`{'Dwight Schrute': [('Jim Halpert', 1.0), ('Stanley Hudson', 0.5)], 'Jim Halpert': [('Dwight Schrute', 0.0)], 'Stanley Hudson': [('Dwight Schrute', 0.5)]}`\n",
    "\n",
    "You can assume that each dictionary in `games` will have the keys `'white_player'`, `'black_player'`, and `'result'` and that the values associated with each of those keys are Strings. There may be duplicated matchups where the same two players are paired in the tournament more than once. These cases should be handled the same as any other game and do not require any special treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #input\n",
    "# [{'white_player': 'Dwight Schrute', 'black_player: 'Jim Halpert',    'result': '1-0'}, \n",
    "#  {'white_player': 'Stanley Hudson', 'black_player': 'Dwight Schrute', 'result': '1/2-1/2'}]\n",
    "\n",
    "# # output\n",
    "# {'Dwight Schrute': [('Jim Halpert', 1.0), ('Stanley Hudson', 0.5)], \n",
    "#  'Jim Halpert': [('Dwight Schrute', 0.0)], \n",
    "#  'Stanley Hudson': [('Dwight Schrute', 0.5)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "demo_games_metadata = [{'white_player': 'Dwight Schrute', 'black_player': 'Jim Halpert', 'result': '1-0'}, {'white_player': 'Stanley Hudson', 'black_player': 'Dwight Schrute', 'result': '1/2-1/2'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dwight Schrute': [('Jim Halpert', 1.0), ('Stanley Hudson', 0.5)],\n",
       " 'Jim Halpert': [('Dwight Schrute', 0.0)],\n",
       " 'Stanley Hudson': [('Dwight Schrute', 0.5)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_player_results(games):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    \n",
    "    game_results = {}\n",
    "    for g in games:\n",
    "        white_player = g['white_player']\n",
    "        black_player = g['black_player']\n",
    "        result = g['result']\n",
    "        if result == '1-0':\n",
    "            white_player_pts = 1.0\n",
    "            black_player_pts = 0.0\n",
    "        elif result == '0-1':\n",
    "            white_player_pts = 0.0\n",
    "            black_player_pts = 1.0\n",
    "        elif result == '1/2-1/2':\n",
    "            white_player_pts = 0.5\n",
    "            black_player_pts = 0.5\n",
    "        else:\n",
    "            raise ValueError('wrong result')\n",
    "        \n",
    "        # put it back to the dictionary\n",
    "        game_results[white_player] = game_results.get(white_player,[])+[(black_player,white_player_pts)]\n",
    "        game_results[black_player] = game_results.get(black_player,[])+[(white_player,black_player_pts)]\n",
    "    \n",
    "    return game_results\n",
    "    \n",
    "# Demo\n",
    "extract_player_results(demo_games_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex1_test",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'48.1 MiB'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ex1_test`: Test cell\n",
    "from run_tests import ex1_test\n",
    "for _ in range(100):\n",
    "    ex1_test(10, 4, extract_player_results)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Run the following cell, even if you skipped Exercise 1.**\n",
    "\n",
    "We are loading a pre-computed solution that will be used in the following sections. The first two entries are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deac,Bogdan-Daniel': [('Giri,A', 0.5),\n",
       "  ('Vachier', 1.0),\n",
       "  ('Mamedyarov,S', 0.5),\n",
       "  ('Grischuk,A', 0.0),\n",
       "  ('So,W', 0.5),\n",
       "  ('Radjabov,T', 0.5),\n",
       "  ('Lupulescu,C', 0.5),\n",
       "  ('Aronian,L', 0.0),\n",
       "  ('Caruana,F', 0.5)],\n",
       " 'Giri,A': [('Deac,Bogdan-Daniel', 0.5),\n",
       "  ('Radjabov,T', 0.5),\n",
       "  ('Lupulescu,C', 0.0),\n",
       "  ('Aronian,L', 0.5),\n",
       "  ('Caruana,F', 0.5),\n",
       "  ('So,W', 0.5),\n",
       "  ('Vachier', 1.0),\n",
       "  ('Grischuk,A', 0.5)]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample result for ex1\n",
    "player_results = test_utils.read_pickle('player_results')\n",
    "{k:v for k, v in list(player_results.items())[:2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2 (1 point)\n",
    "\n",
    "Our next task is to compute the total tournament score for each player.\n",
    "\n",
    "Fill in the function `calculate_score(player_results)` satisfying the following requirements:\n",
    "\n",
    "Given a dictionary `player_results` mapping player names to their tournament results (similar to the output of Excercise 1), create a **new** dictionary `player_scores` that maps each player (String) to their total score for the tournament (Float).\n",
    "\n",
    "For example, given the following input: \n",
    "\n",
    "`{'Angela Martin': [('Oscar Martinez', 1.0), ('Kevin Malone', 0.5), ('Andy Bernard', 0.0)], 'Michael Scott': [('Pam Halpert', 0.0), ('Toby Flenderson', 0.0), ('Todd Packer', 0.0)]}`\n",
    "\n",
    "Your function should output:\n",
    "\n",
    "`{'Angela Martin': 1.5, 'Michael Scott': 0.0}`\n",
    "\n",
    "(Michael isn't exactly a chess prodigy...)\n",
    "\n",
    "You can assume that the lists keyed to each String in the input will be of the form (String, Float). You do not need to worry about verifying that all of the games implied by the input are present. If you look closely at the example, you will see that this is **not** the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "demo_player_results = {'Angela Martin': [('Oscar Martinez', 1.0), ('Kevin Malone', 0.5), ('Andy Bernard', 0.0)], 'Michael Scott': [('Pam Halpert', 0.0), ('Toby Flenderson', 0.0), ('Todd Packer', 0.0)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angela Martin': 1.5, 'Michael Scott': 0.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def calculate_score(player_results):\n",
    "    total_keys = []\n",
    "    for keys in player_results.keys():\n",
    "        total_keys.append(keys)\n",
    "    \n",
    "    scores = []\n",
    "    for value in player_results.values():\n",
    "        for name_set in value:\n",
    "            scores.append(name_set[1])\n",
    "    \n",
    "    calcuated = [sum(scores[i:i+3])for i in range(0, len(scores),3)]\n",
    "    return dict(zip(total_keys, calcuated))\n",
    "    \n",
    "\n",
    "# Demo\n",
    "calculate_score(demo_player_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angela Martin': 1.5, 'Michael Scott': 0.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_score(player_results):\n",
    "    score_dict = {}\n",
    "    for player, results in player_results.items():\n",
    "        score = sum(result[1] for result in results)\n",
    "        score_dict[player] = score\n",
    "    return score_dict\n",
    "\n",
    "# Demo\n",
    "calculate_score(demo_player_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2_test",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'49.1 MiB'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ex2_test`: Test cell\n",
    "from run_tests import ex2_test\n",
    "for _ in range(200):\n",
    "    ex2_test(10, 4, calculate_score)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Run the following cell, even if you skipped Exercise 2.**\n",
    "\n",
    "We are loading a pre-computed solution that will be used in the following sections. The first two entries are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deac,Bogdan-Daniel': 4.0, 'Giri,A': 4.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample result for ex2\n",
    "player_scores = test_utils.read_pickle('player_scores')\n",
    "{k:v for k, v in list(player_scores.items())[:2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3 (2 points)\n",
    "\n",
    "Our next task is to extract the Elo rating of each player from the metadata.\n",
    "\n",
    "Fill in the function `extract_ratings(games)` to satisfy the following requirements:\n",
    "\n",
    "Given a list of dictionaries, `games`, create a dictionary `player_ratings` that maps each player to their Elo rating before the tournament. You can assume that each dictionary in `games` will have the following keys and value types: `'white_player'`: (String), `'black_player'`: (String), `'white_rating'`: (Integer), and `'black_rating'`: (Integer).\n",
    "\n",
    "Additionally, if the same player has different ratings in the input, your function should raise a `ValueError`.\n",
    "\n",
    "For example:\n",
    "\n",
    "Input : `[{'white_player': 'Jim Halpert', 'black_player': 'Darryl Philbin', 'white_rating': 1600, 'black_rating': 1800}, {'white_player': 'Darryl Philbin', 'black_player': 'Phyllis Vance', 'white_rating': 1800, 'black_rating': 1700}]`\n",
    "\n",
    "Output : `{'Darryl Philbin': 1800, 'Jim Halpert': 1600, 'Phyllis Vance': 1700}`\n",
    "\n",
    "Input : `[{'white_player': 'Jim Halpert', 'black_player': 'Darryl Philbin', 'white_rating': 1600, 'black_rating': 1800}, {'white_player': 'Darryl Philbin', 'black_player': 'Phyllis Vance', 'white_rating': 1850, 'black_rating': 1700}]`\n",
    "\n",
    "Here `'Darryl Philbin'` has two ratings: 1800 in his first game and 1850 in his second. Your function should raise a `ValueError`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "demo_metadata_good = [{'white_player': 'Jim Halpert', 'black_player': 'Darryl Philbin', 'white_rating': 1600, 'black_rating': 1800}, {'white_player': 'Darryl Philbin', 'black_player': 'Phyllis Vance', 'white_rating': 1800, 'black_rating': 1700}]\n",
    "demo_metadata_bad = [{'white_player': 'Jim Halpert', 'black_player': 'Darryl Philbin', 'white_rating': 1600, 'black_rating': 1800}, {'white_player': 'Darryl Philbin', 'black_player': 'Phyllis Vance', 'white_rating': 1850, 'black_rating': 1700}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly raised ValueError\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Jim Halpert': 1600, 'Darryl Philbin': 1800, 'Phyllis Vance': 1700}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ratings(games):\n",
    "    player_ratings = {}\n",
    "    for game in games:\n",
    "        white_player = game['white_player']\n",
    "        black_player = game['black_player']\n",
    "        white_rating = game['white_rating']\n",
    "        black_rating = game['black_rating']\n",
    "\n",
    "        if white_player in player_ratings and player_ratings[white_player] != white_rating:\n",
    "            raise ValueError(f\"Inconsistent ratings for player {white_player}\")\n",
    "        if black_player in player_ratings and player_ratings[black_player] != black_rating:\n",
    "            raise ValueError(f\"Inconsistent ratings for player {black_player}\")\n",
    "\n",
    "        player_ratings[white_player] = white_rating\n",
    "        player_ratings[black_player] = black_rating\n",
    "\n",
    "    return player_ratings\n",
    "\n",
    "    \n",
    "# Demo\n",
    "try:\n",
    "    extract_ratings(demo_metadata_bad)\n",
    "    print('This should raise a ValueError')\n",
    "except ValueError:\n",
    "    print('Correctly raised ValueError')\n",
    "extract_ratings(demo_metadata_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex3_test",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# `ex3_test`: Test cell\n",
    "from run_tests import ex3_test\n",
    "for _ in range(200):\n",
    "    ex3_test(10, 4, extract_ratings)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Run the following cell, even if you skipped Exercise 3.**\n",
    "\n",
    "We are loading a pre-computed solution that will be used in the following sections. The first two entries are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deac,Bogdan-Daniel': 2627, 'Giri,A': 2780}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample result for ex3\n",
    "player_ratings = test_utils.read_pickle('player_ratings')\n",
    "{k:v for k, v in list(player_ratings.items())[:2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 4 (1 point)\n",
    "\n",
    "The last task before we begin analysis is to implement some functionality to calculate the expected result of a match based on the Elo ratings of each player.\n",
    "\n",
    "Fill out the function `expected_match_score(r_player, r_opponent)` to satisfy the following requirements:\n",
    "\n",
    "Given a player's rating (Integer) and their opponent's rating (Integer), compute the player's expected score in a game against that opponent. The formula for the expected score is:\n",
    "\n",
    "$$\\text{Expected Score} =  \\frac{1}{1 + 10^{d}}$$\n",
    "where \n",
    "$$d = \\frac{r_{\\text{opponent}} - r_{\\text{player}}}{400}$$\n",
    "\n",
    "Output the expected score as a Float. **Do not round**.\n",
    "\n",
    "For example:\n",
    "\n",
    "`expected_match_score(1900, 1500)` should return about `0.909`  \n",
    "`expected_match_score(1500, 1500)` should return about `0.5`  \n",
    "`expected_match_score(1900, 1700)` should return about `0.76`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "demo_ratings = [(1900, 1500), (1500, 1500), (1900, 1700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_match_score(1900, 1500) = 0.9090909090909091\n",
      "expected_match_score(1500, 1500) = 0.5\n",
      "expected_match_score(1900, 1700) = 0.7597469266479578\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def expected_match_score(r_player, r_opponent):\n",
    "    d = (r_opponent - r_player) / 400\n",
    "    expected_score = 1 / (1 + math.pow(10, d))\n",
    "    return expected_score\n",
    "\n",
    "\n",
    "# Demo\n",
    "for rp, ro in demo_ratings:\n",
    "    print(f'expected_match_score({rp}, {ro}) = {expected_match_score(rp, ro)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex4_test",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'49.1 MiB'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ex4_test`: Test cell\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "from run_tests import ex4_test\n",
    "for _ in range(200):\n",
    "    ex4_test(expected_match_score)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Aside - Functional Programming\n",
    "\n",
    "It is often useful to write functions which take other functions as arguments. Inside of your function, the functional argument is called in a consistent way. This allows the caller of your function to customize it's behavior. \n",
    "\n",
    "Here is an over-engineered arithmetic calculator as an example. These functions define mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# add\n",
    "def a(a, b):\n",
    "    return a+b\n",
    "# subtract\n",
    "def s(a, b):\n",
    "    return a-b\n",
    "# multiply\n",
    "def m(a, b):\n",
    "    return a*b\n",
    "# divide\n",
    "def d(a,b):\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This function, `calc`, takes the two numbers as an argument and a third argument which determines how they are combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def calc(a, b, opp):\n",
    "    return opp(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now we can use any function that takes two arguments, like the 4 defined above to determine the behavior of `calc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc(3,5,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc(3,5,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 5 (3 points)\n",
    "\n",
    "Our next task is to write some functionality to determine each player's expected tournament score.\n",
    "\n",
    "Fill in the function `expected_tournament_score(player_results, player_ratings, es_func)` to satisfy the following requirements:\n",
    "\n",
    "Given a dictionary, `player_results`, mapping players to their tournament results as a list of tuples (similar to the output from Exercise 1) and a dictionary, `player_ratings`, mapping players to their Elo ratings, compute the **total** expected score for each player (you only need to compute total expected score for players that are keys in `player_results`). The total expected score is simply the sum of the expected scores for each of that players games. Output the results as a dictionary mapping players (String) to their expected tournament score (Float).\n",
    "\n",
    "The third argument `es_func` is a function that takes two arguments (the player's rating and opponent's rating respectively) and returns an \"expected score\". You should use it to compute the expected scores for this exercise. **It might not be the same as the solution to Exercise 4!**\n",
    "\n",
    "A call to `es_func(1450, 1575)` inside of your function would compute the \"expected score\" for the 1450-rated player against a 1575-rated player.\n",
    "\n",
    "For example given:\n",
    "\n",
    "`player_results = {'Angela Martin': [('Dwight Schrute', 1.0), ('Stanley Hudson', 0.5)], 'Dwight Schrute': [('Angela Martin', 0.0), ('Jim Halpert', 0.5)]}`\n",
    "\n",
    "`player_ratings = {'Angela Martin': 1600, 'Dwight Schrute': 1750, 'Stanley Hudson': 1800, 'Jim Halpert': 1700}`\n",
    "\n",
    "`es_func = lambda r_player, r_opponent: float(r_player - r_opponent)`\n",
    "\n",
    "The output would be:\n",
    "\n",
    "`{'Angela Martin': -350.0, 'Dwight Schrute': 200.0}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "demo_player_results = {'Angela Martin': [('Dwight Schrute', 1.0), ('Stanley Hudson', 0.5)], 'Dwight Schrute': [('Angela Martin', 0.0), ('Jim Halpert', 0.5)]}\n",
    "demo_player_ratings = {'Angela Martin': 1600, 'Dwight Schrute': 1750, 'Stanley Hudson': 1800, 'Jim Halpert': 1700}\n",
    "demo_es_func = lambda r_player, r_opponent: float(r_player - r_opponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Angela Martin': -350.0, 'Dwight Schrute': 200.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def expected_tournament_score(player_results, player_ratings, es_func):\n",
    "\n",
    "def expected_tournament_score(player_results, player_ratings, es_func):\n",
    "    expected_scores = {}\n",
    "    for player, results in player_results.items():\n",
    "        expected_score = 0\n",
    "        for opponent, result in results:\n",
    "            if opponent not in player_ratings:\n",
    "                continue\n",
    "            r_player = player_ratings[player]\n",
    "            r_opponent = player_ratings[opponent]\n",
    "            expected_score += es_func(r_player, r_opponent)\n",
    "        expected_scores[player] = expected_score\n",
    "    return expected_scores\n",
    "\n",
    "\n",
    "# Demo\n",
    "expected_tournament_score(demo_player_results, demo_player_ratings, demo_es_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex5_test",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'49.3 MiB'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ex5_test`: Test cell\n",
    "from run_tests import ex5_test\n",
    "for _ in range(200):\n",
    "    ex5_test(10, 4, expected_tournament_score)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Run the following cell, even if you skipped Exercise 5.**\n",
    "\n",
    "We are loading a pre-computed solution that will be used in the following sections. The first two entries are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deac,Bogdan-Daniel': 2.827559638896802, 'Giri,A': 4.389932419673484}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample result for ex5\n",
    "player_expected_score = test_utils.read_pickle('player_expected_score')\n",
    "{k:v for k, v in list(player_expected_score.items())[:2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 6 (2 points)\n",
    "\n",
    "Fill in the function `compute_final_ratings(player_scores, expected_player_scores, player_ratings)` to meet the following requirements:\n",
    "\n",
    "Given three dictionaries:\n",
    "\n",
    "* `player_scores`: mapping players (String) to their observed tournament scores (Float)  \n",
    "* `expected_player_scores`: mapping players (String) to their expected tournament scores (Float)  \n",
    "* `player_ratings`: mapping players (String) to their pre-tournament Elo ratings (Float)  \n",
    "\n",
    "calculate each player's post-tournament Elo ratings using this formula:\n",
    "\n",
    "$$\\text{Rating}_{\\text{post}} = \\text{Rating}_{\\text{pre}} + 10(\\text{Score}_{\\text{observed}} - \\text{Score}_{\\text{expected}})$$\n",
    "\n",
    "Return a dictionary mapping each player (String) to their post-tournament rating **rounded to the nearest integer**.\n",
    "\n",
    "You can assume that all keys are common between the three input dictionaries.\n",
    "\n",
    "For example:\n",
    "\n",
    "`player_scores = {'Jim Halpert': 3.0, 'Dwight Schrute': 4.0, 'Stanley Hudson': 3.0}`\n",
    "\n",
    "`expected_player_scores = {'Jim Halpert': 2.736, 'Dwight Schrute': 4.67, 'Stanley Hudson': 2.85}`\n",
    "\n",
    "`player_ratings = {'Jim Halpert': 1500, 'Dwight Schrute': 1575, 'Stanley Hudson': 1452}`\n",
    "\n",
    "Results:\n",
    "`{'Jim Halpert': 1503, 'Dwight Schrute': 1568, 'Stanley Hudson': 1454}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "demo_player_scores = {'Jim Halpert': 3.0, 'Dwight Schrute': 4.0, 'Stanley Hudson': 3.0}\n",
    "demo_expected_player_scores = {'Jim Halpert': 2.736, 'Dwight Schrute': 4.67, 'Stanley Hudson': 2.85}\n",
    "demo_player_ratings = {'Jim Halpert': 1500, 'Dwight Schrute': 1575, 'Stanley Hudson': 1452}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jim Halpert': 1503, 'Dwight Schrute': 1568, 'Stanley Hudson': 1454}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def compute_final_ratings(player_scores, expected_player_scores, player_ratings):\n",
    "def compute_final_ratings(player_scores, expected_player_scores, player_ratings):\n",
    "    final_ratings = {}\n",
    "    for player in player_scores:\n",
    "        score_observed = player_scores[player]\n",
    "        score_expected = expected_player_scores[player]\n",
    "        rating_pre = player_ratings[player]\n",
    "        rating_post = rating_pre + 10 * (score_observed - score_expected)\n",
    "        final_ratings[player] = round(rating_post)\n",
    "    return final_ratings\n",
    "\n",
    "\n",
    "# Demo\n",
    "compute_final_ratings(demo_player_scores, demo_expected_player_scores, demo_player_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex6_test",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'49.3 MiB'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ex6_test`: Test cell\n",
    "from run_tests import ex6_test\n",
    "for _ in range(200):\n",
    "    ex6_test(10, compute_final_ratings)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Run the following cell, even if you skipped Exercise 6.**\n",
    "\n",
    "We are loading a pre-computed solution that will be used in the following sections. The first two entries are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deac,Bogdan-Daniel': 2639, 'Giri,A': 2776}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample result for ex6\n",
    "player_final_ratings = test_utils.read_pickle('player_final_ratings')\n",
    "{k:v for k, v in list(player_final_ratings.items())[:2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Exercise 7 (2 points)\n",
    "\n",
    "The last task we have is to compute the change in rating. This isn't just an intermediate step in Exercise 6, because we have to handle some special cases as well.\n",
    "\n",
    "Fill in the function `compute_deltas(old_ratings, new_ratings)` to meet the following requirements:\n",
    "\n",
    "Given dictionaries `old_ratings` mapping players (String) to their pre-tournament Elo ratings (Integer) and `new_ratings` mapping players (String) to their post-tournament Elo ratings, determine the change in each player's rating. Return your result as a dictionary mapping players (String) to their delta (Integer).\n",
    "\n",
    "Compute the delta as $$\\Delta = \\text{Rating}_{\\text{new}} - \\text{Rating}_{\\text{old}}$$\n",
    "\n",
    "If a player is not present as a key in the `old_ratings` input but is present as a key in the `new_ratings` input, then assume this is a new player with a starting rating of `1200`. Likewise, if a player is present as a key in `old_ratings` but is not present in `new_ratings`, assume that player did not play in the tournament and their rating is unchanged.\n",
    "\n",
    "For example:\n",
    "\n",
    "`old_ratings = {'Ryan Howard': 1755, 'Dwight Schrute': 1675}`\n",
    "\n",
    "`new_ratings = {'Michael Scott': 1250, 'Ryan Howard': 1750}`\n",
    "\n",
    "Should return:\n",
    "\n",
    "`{'Michael Scott': 50, 'Ryan Howard': -5, 'Dwight Schrute': 0}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "demo_old_ratings = {'Ryan Howard': 1755, 'Dwight Schrute': 1675}\n",
    "demo_new_ratings = {'Michael Scott': 1250, 'Ryan Howard': 1750}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Michael Scott': 50, 'Ryan Howard': -5, 'Dwight Schrute': 0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def compute_deltas(old_ratings, new_ratings):\n",
    "def compute_deltas(old_ratings, new_ratings):\n",
    "    deltas = {}\n",
    "    for player in new_ratings:\n",
    "        if player in old_ratings:\n",
    "            delta = new_ratings[player] - old_ratings[player]\n",
    "        else:\n",
    "            delta = new_ratings[player] - 1200\n",
    "        deltas[player] = delta\n",
    "    for player in old_ratings:\n",
    "        if player not in new_ratings:\n",
    "            deltas[player] = 0\n",
    "    return deltas\n",
    "\n",
    "\n",
    "# Demo\n",
    "compute_deltas(demo_old_ratings, demo_new_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below runs your function **many times**. Remove or comment out any `print` statements to avoid generating excessive output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "ex7_test",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'49.3 MiB'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `ex7_test`: Test cell\n",
    "from run_tests import ex7_test\n",
    "for _ in range(200):\n",
    "    ex7_test(10, compute_deltas)\n",
    "print('Passed!')\n",
    "\n",
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n",
    "test_utils.get_mem_usage_str()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Wrapping up\n",
    "After parsing all of the information from the text file, we can display a summary of the tournament results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial Rating</th>\n",
       "      <th>Score</th>\n",
       "      <th>Expected Score</th>\n",
       "      <th>Final Rating</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Deac,Bogdan-Daniel</th>\n",
       "      <td>2627</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.827560</td>\n",
       "      <td>2639</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giri,A</th>\n",
       "      <td>2780</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.389932</td>\n",
       "      <td>2776</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lupulescu,C</th>\n",
       "      <td>2656</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.197736</td>\n",
       "      <td>2659</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aronian,L</th>\n",
       "      <td>2781</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.395254</td>\n",
       "      <td>2782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grischuk,A</th>\n",
       "      <td>2776</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.848488</td>\n",
       "      <td>2778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vachier</th>\n",
       "      <td>2760</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.131705</td>\n",
       "      <td>2749</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mamedyarov,S</th>\n",
       "      <td>2770</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.278985</td>\n",
       "      <td>2782</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So,W</th>\n",
       "      <td>2770</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.764597</td>\n",
       "      <td>2772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Caruana,F</th>\n",
       "      <td>2820</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.876846</td>\n",
       "      <td>2806</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radjabov,T</th>\n",
       "      <td>2765</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.288897</td>\n",
       "      <td>2762</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Initial Rating  Score  Expected Score  Final Rating  Delta\n",
       "Deac,Bogdan-Daniel            2627    4.0        2.827560          2639     12\n",
       "Giri,A                        2780    4.0        4.389932          2776     -4\n",
       "Lupulescu,C                   2656    3.5        3.197736          2659      3\n",
       "Aronian,L                     2781    4.5        4.395254          2782      1\n",
       "Grischuk,A                    2776    5.0        4.848488          2778      2\n",
       "Vachier                       2760    3.0        4.131705          2749    -11\n",
       "Mamedyarov,S                  2770    5.5        4.278985          2782     12\n",
       "So,W                          2770    5.0        4.764597          2772      2\n",
       "Caruana,F                     2820    3.5        4.876846          2806    -14\n",
       "Radjabov,T                    2765    3.0        3.288897          2762     -3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(index=player_scores.keys())\n",
    "df['Initial Rating'] = pd.Series(player_ratings)\n",
    "df['Score'] = pd.Series(player_scores)\n",
    "df['Expected Score'] = pd.Series(player_expected_score)\n",
    "df['Final Rating'] = pd.Series(player_final_ratings)\n",
    "df['Delta'] = pd.Series(test_utils.read_pickle('player_deltas'))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Fin!** You’ve reached the end of this part. Don’t forget to restart and run all cells again to make sure it’s all working when run in sequence; and make sure your work passes the submission process. Good luck!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3fd46944e962958c55dea57c2958abafb59d97d99849a82f15f0d5b255610906"
  },
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
